{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darren\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country / territory of asylum/residence</th>\n",
       "      <th>Origin</th>\n",
       "      <th>RSD procedure type / level</th>\n",
       "      <th>decisions_recognized</th>\n",
       "      <th>decisions_other</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>Otherwise_closed</th>\n",
       "      <th>Total decisions</th>\n",
       "      <th>Successful</th>\n",
       "      <th>...</th>\n",
       "      <th>origin_to_target_dist</th>\n",
       "      <th>HDI</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>acceptance_rate</th>\n",
       "      <th>accepted/rejected</th>\n",
       "      <th>Encoded procedure type</th>\n",
       "      <th>Encoded Target Country</th>\n",
       "      <th>Encoded Origin</th>\n",
       "      <th>log_origin_to_target_dist</th>\n",
       "      <th>log_GDP_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Angola</td>\n",
       "      <td>G / AR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.61</td>\n",
       "      <td>30.896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601402</td>\n",
       "      <td>7.601402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Country / territory of asylum/residence  Origin  \\\n",
       "0  2001                            South Africa  Angola   \n",
       "\n",
       "  RSD procedure type / level  decisions_recognized  decisions_other  Rejected  \\\n",
       "0                     G / AR                   0.0              0.0       0.0   \n",
       "\n",
       "   Otherwise_closed  Total decisions  Successful  ...  origin_to_target_dist  \\\n",
       "0               1.0              0.0         0.0  ...                   2001   \n",
       "\n",
       "    HDI  Unemployment rate acceptance_rate  accepted/rejected  \\\n",
       "0  0.61             30.896             0.0                  0   \n",
       "\n",
       "   Encoded procedure type  Encoded Target Country  Encoded Origin  \\\n",
       "0                       1                     135               3   \n",
       "\n",
       "  log_origin_to_target_dist  log_GDP_difference  \n",
       "0                  7.601402            7.601402  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"../cleaned_data/cleaned_asylum_seekers_added.csv\")\n",
    "\n",
    "# Remove records from HDI column where values = '..'\n",
    "data = data[data['HDI'] != '..']\n",
    "data['GDP_difference'] = data['GDP_difference'].abs() \n",
    "data['GDP_difference'] = data[(data['GDP_difference'] != 0)]\n",
    "\n",
    "# Log to transform data\n",
    "data['origin_to_target_dist'] = data[(data['origin_to_target_dist'] != 0)]\n",
    "data['log_origin_to_target_dist'] = data['origin_to_target_dist'].apply(lambda x: math.log(x))\n",
    "\n",
    "data['log_GDP_difference'] = data['GDP_difference'].apply(lambda x: math.log(x))\n",
    "\n",
    "# Convert to float type\n",
    "data['HDI'] = data['HDI'].astype('float64')\n",
    "\n",
    "# Remove null values from all records\n",
    "data = data.dropna()\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Unemployment rate', 'Encoded procedure type', 'log_origin_to_target_dist'] # Declare the columns names\n",
    "\n",
    "# Features\n",
    "x = data[col_names]  \n",
    "\n",
    "# Target Variable\n",
    "y = data['accepted/rejected']\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Decision Tree classifer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional param-> max_depth, random_state\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.8220455298405036\n"
     ]
    }
   ],
   "source": [
    "# Predict test set labels\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: \", (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using entropy as criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.8220455298405036\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion = 'entropy')\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(x_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred = dt_entropy.predict(x_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Accuracy achieved by using entropy: ', accuracy_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GINI as criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using the gini index:  0.8220455298405036\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt_gini, set 'gini' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(criterion = 'gini')\n",
    "\n",
    "# Fit dt_gini to the training set\n",
    "dt_gini.fit(x_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred = dt_gini.predict(x_test)\n",
    "\n",
    "# Evaluate accuracy_gini\n",
    "accuracy_gini = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy_gini\n",
    "print('Accuracy achieved by using the gini index: ', accuracy_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Decision Tree with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved using hyperparameters:  0.8220455298405036\n"
     ]
    }
   ],
   "source": [
    "# optional param-> max_depth, random_state\n",
    "dt_hp = DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
    "                       max_depth=15, max_features=2, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=5, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, random_state=None)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dt_hp.fit(x_train,y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy achieved using hyperparameters: \", (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "### Define a grid of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_dt = {'max_depth': [2, 3, 4], 'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]}\n",
    "# # 'HDI','Unemployment rate','GDP_difference','origin_to_target_dist','Encoded Origin', 'Encoded Target Country'\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 8, 10, 12],\n",
    "    'n_estimators': [50, 80, 100, 200]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [5, 10, 15, 20],\n",
       "                         'max_features': [2, 3],\n",
       "                         'min_samples_leaf': [2, 3, 4, 5],\n",
       "                         'min_samples_split': [2, 4, 8, 10, 12],\n",
       "                         'n_estimators': [50, 80, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1)\n",
    "\n",
    "# Fit grid search to data\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameteres:  {'bootstrap': True, 'max_depth': 15, 'max_features': 2, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200} \n",
      "\n",
      "Best Grid:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Reference from: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Extract the best params\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameteres: \", best_params, \"\\n\")\n",
    "\n",
    "# Extract the best estimator\n",
    "best_grid = grid_search.best_estimator_\n",
    "print(\"Best Grid: \", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212337341648578\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "best_result = grid_search.best_score_\n",
    "print(\"Accuracy:\", best_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
